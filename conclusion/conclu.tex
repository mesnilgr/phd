
\chapter{Conclusion Générale}

L'apprentissage de réseaux de neurones profonds a évolué très rapidement au
cours de la réalisation de ce doctorat. Ces changements sont reflétés dans nos
travaux qui ont suivi l'évolution riche de la recherche en architectures
profondes des dernières années.
\\

Nous avons commencé par présenter de nombreuses techniques d'apprentissage non
supervisé, puis comment les mettre en oeuvre pour gagner une compétition de
transfert d'apprentissage ou améliorer la performance d'un système de vision
tout en réduisant la dimensionnalité de l'espace d'entrée original. Ces
solutions nous ont permis d'apprendre un espace sémantique de représentation.

Dans le chapitre \ref{chap:utlc}, nous avons présenté des solutions
performantes pour extraire un espace sémantique de représentation permettant
une meilleure séparabilité linéaire. La PCA transductive a aussi permis
d'effectuer un transfert d'apprentissage tout en limitant la présence de bruit
préjudiciable à une classification linéaire. Ces idées ont permis d'améliorer
notre solution finale soumise lors de la compétition et ainsi de remporter la
première place.

Dans le chapitre \ref{chap:ob}, nous avons appliqué ces idées à un espace
d'entrée de dimension élevée mais structurée. La qualité de l'espace sémantique
de représentation par rapport à l'espace d'entrée original a nettement
progressé en matière de compression d'information et de performance. Nous avons
aussi démontré la capacité des réseaux de neurones à effectuer du transfert
d'apprentissage. 
\\

Ensuite, nos intuitions concernant l'espace sémantique des représentations
apprises ont été résumées dans nos recherches sur l'amélioration du mixage lors
du processus d'échantillonnage effectué dans les couches profondes les plus
abstraites (chapitre \ref{chap:mixing}). Il a été très intéressant de sortir du
cadre probabiliste de l'échantillonnage des RBMs pour s'intéresser à des
intuitions plus géométriques sur la sémantique de l'espace et se déplacer ainsi
sur la variété. 

La présentation des vidéos permettant un déplacement en images sur la variété
des exemples d'entraînement a donné lieu à d'intéressantes conversations
scientifiques lors de plusieurs colloques. Ces vidéos contenaient des chiffres
passant d'une classe à l'autre ou des visages changeant d'expression.
\\

Pour terminer, nous avons étudié deux cas où l'espace sémantique est appris
soit en sortie soit en entrée du réseau de neurones. L'utilisation
d'architectures prometteuses telles que les réseaux de neurones récurrents a
été la base d'une transition vers l'apprentissage supervisé d'espaces
sémantiques associés au langage (chapitre \ref{chap:rnn}).  À la fin du processus
d'apprentissage, nous avons observé que l'espace sémantique était structuré
sous forme de grappes de mots possédant la même classe.

À l'heure actuelle, les récents succès de l'industrie résident dans
l'utilisation d'ensemble de données de très grande échelle.  Avec un grand
ensemble de données (plusieurs millions d'exemples), le chapitre \ref{chap:mlj}
se concentre sur le transfert d'apprentissage au travers d'un espace sémantique
multidomaine. Un aspect intéressant de ce travail a été de sortir du
cadre de maximisation de la vraisemblance pour optimiser un système à base de
maximisation de marge pour une classification en haute dimension.  \\

Dans le futur, nous espérons poursuivre nos travaux de recherche pour apprendre
des espaces sémantiques avec une structure plus riche et un nombre de domaine
arbitraire. L'apprentissage non supervisé n'atteint pas encore le niveau des
performances récemment obtenues en apprentissage supervisé d'architectures
profondes pour des tâches de vision, de reconnaissance de la parole ou de
traitement du langage. Il est possible que le problème actuel puisse être
résolu autrement qu'avec une classique erreur de reconstruction accompagnée
d'une régularisation sur les paramètres. Des contraintes différentes peuvent
être envisagées. J'espère pouvoir apporter des solutions originales à ce
problème dans les années à venir.

\chapter*{Bibliographie Personnelle}

\begin{description}
\item[2015] \hfill \\
\begin{description}
\item \uline{Grégoire Mesnil}, Yann Dauphin, Kaisheng Yao, Yoshua Bengio, Li Deng, Dilek Hakkani-Tur, Xiaodong He, Larry Heck, Gokhan Tur, Dong Yu and Geoffrey Zweig {\bf Using Recurrent Neural Networks for Slot Filling in Spoken Language Understanding} (2015) IEEE Transactions on Audio, Signal and Language Processing, in press
\vspace{0.1cm}
\item \uline{Grégoire Mesnil}, Salah Rifai, Antoine Bordes, Xavier Glorot, Yoshua Bengio and Pascal Vincent
{\bf Unsupervised Learning of Object Detections Semantics for Scene Categorization}
(2015) 
 Pattern Recognition Applications and Methods, Advances in Intelligent Systems and Computing, pages 209-224
\vspace{0.1cm}
\item \uline{Grégoire Mesnil}, Tomas Mikolov, Marc'Aurelio Ranzato and Yoshua Bengio {\bf Ensemble of Generative and Discriminative Techniques for Sentiment Analysis of Movie Reviews} (2015) International Conference on Learning Representations (submitted in the workshop track)
\vspace{0.1cm}
\end{description}

\item[2014] \hfill \\
\begin{description}
\item Yelong Shen, Xiaodong He, Jianfeng Gao, Li Deng and \uline{Grégoire Mesnil}
{\bf  Learning Semantic Representations Using Convolutional Neural Networks for Web Search}
(2014) Proceedings of the World Wide Web Conference, poster.
\vspace{0.1cm}
\item Yelong Shen, Xiaodong He, Jianfeng Gao, Li Deng and \uline{Grégoire Mesnil}
{\bf  A Convolutional Neural Network based Latent Semantic Model for Web Search}
(2014) Proceedings of the Conference on Knowledge and Information Management.
\vspace{0.1cm}
\end{description}

\item[2013] \hfill \\
\begin{description}
\item \uline{Grégoire Mesnil}, Xiaodong He, Li Deng and Yoshua Bengio
{\bf Investigation of Recurrent-Neural-Network Architectures and Learning Methods for Spoken Language Understanding}
(2013) Proceedings of the Interspeech Conference
\vspace{0.1cm}
\item Yoshua Bengio, \uline{Grégoire Mesnil}, Yann Dauphin and Salah Rifai
{\bf Better Mixing via Deep Representations} (2013) 
Proceedings of the 30th International Conference on Machine Learning 
\vspace{0.1cm}
\item \uline{Grégoire Mesnil}, Antoine Bordes, Jason Weston,
Gal Chechik and Yoshua Bengio, {\bf Learning Semantic Representations Of
Objects and Their Parts} (2013) Machine Learning Journal, volume 94, pages 281–301
\vspace{0.1cm}
\item \uline{Grégoire Mesnil}, Salah Rifai, Xavier Glorot, Antoine Bordes,
Yoshua Bengio and Pascal Vincent, {\bf Unsupervised and Transfer Learning under Uncertainty:
from Object Detections to Scene Categorization} (2013) Proceedings of the International Conference on Pattern
Recognition Applications and Methods (oral)
\vspace{0.1cm}
\end{description}

\item[2012] \hfill \\
\begin{description}
\item \uline{Grégoire Mesnil}, Salah Rifai, Yann Dauphin,  Yoshua Bengio and
Pascal Vincent, {\bf Surfing on the Manifold } (2012) Learning Workshop
(poster), Snowbird, Utah, U.S.A.
\vspace{0.1cm}
\item
\uline{Grégoire Mesnil}, Yann Dauphin, Xavier Glorot, Salah Rifai, Yoshua Bengio, et al. {\bf Unsupervised and Transfer Learning Challenge: a Deep Learning Approach} (2012) Journal of Machine Learning Workshop and Conference Papers,
Proceedings of the Unsupervised and Transfer Learning challenge and workshop, pages 97-110
\vspace{0.1cm}
\end{description}

\item[2011] \hfill \\
\begin{description}
\item \uline{Grégoire Mesnil}, Salah Rifai, Xavier Glorot, Antoine Bordes, Pascal Vincent and Yoshua Bengio, {\bf Exploiting context-based Information for Scene Categorization} (2011) Neural Information Processing Systems Workshop on Learning Semantics (poster)
\vspace{0.1cm}
\item
Salah Rifai, \uline{Grégoire Mesnil}, Pascal Vincent, Xavier Muller, Yoshua Bengio, Yann Dauphin and Xavier Glorot, {\bf Higher Order Contractive Auto-Encoder} (2011) Proceedings of the European Conference on Machine Learning
\vspace{0.1cm}
\item
Salah Rifai, Xavier Muller, \uline{Grégoire Mesnil}, Yoshua Bengio and Pascal Vincent, {\bf Learning Invariant features through local space contraction} in Technical Report 1360. Département d'informatique et de recherche opérationnelle. Université de Montréal 2011.
\end{description}

\end{description}


