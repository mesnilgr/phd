\chapter{Pr\'{e}ambule au Premier Article }

\section{D\'{e}tails de l'article}

{\bf Unsupervised and Transfer Learning Challenge: a Deep Learning Approach}
Gr\'{e}goire Mesnil, Yann Dauphin, Xavier Glorot, Salah Rifai, Yoshua Bengio,
Ian Goodfellow, Erick Lavoie, Xavier Muller, Guillaume Desjardins, David
Warde-Farley, Pascal Vincent, Aaron Courville and James Bergstra. {\it Journal
of Machine Learning Research: Proceedings of the Unsupervised and Transfer
Learning Challenge and workshop}, pages $97-110$, $2012$ \\

{\it Contribution Personnelle} Cette comp\'{e}tition faisait partie du travail
pratique d'un cours de Yoshua Bengio. Yann Dauphin, Xavier Glorot, Salah Rifai
et moi-m\^{e}me avons d\'{e}cid\'{e} de former un noyau dur pour remporter la
comp\'{e}tition (plus de 800 entr\'{e}es \`{a} nous 4 sur une courte
p\'{e}riode avec plusieurs centaines de comp\'{e}titeurs).  J'ai propos\'{e}
plusieurs solutions d\'{e}cisives pour cette victoire comme la
transductive-PCA, et plusieurs de mes entr\'{e}es nous ont permis de remporter
la premi\`{e}re place. Une partie de mon code a \'{e}t\'{e} mis \`{a}
disposition des autres \'{e}tudiants sous forme de tutorial afin de leur
permettre de participer et d'utilser notre cluster de calcul. Par la suite,
J'ai dirig\'{e} la r\'{e}daction de l'article en collaboration avec tous les
co-auteurs et pr\'{e}par\'{e} la pr\'{e}sentation donn\'{e}e par Yann Dauphin
lors de la conf\'{e}rence ICML 2012. Le papier a remport\'{e} le PASCAL 2 UTLC
best paper award. 

\section{Contexte}

\`{A} cette \'{e}poque, l'apprentissage de repr\'{e}sentations non
supervis\'{e} commence \`{a} prendre son essor mais de nombreux scientifiques
sont encore suspicieux vis-\`{a}-vis des architectures profondes à réseaux de
neurones. Cette victoire a contribu\'{e} \`{a} montrer que ces techniques
pouvaient rivaliser avec d'autres m\'{e}thodes \`{a} l'\'{e}tat de l'art comme
les SVMs.

\section{Contributions}

Plusieurs des techniques pr\'{e}sent\'{e}es dans ce papier ont par la suite
obtenu des publications dans des journaux ou des conf\'{e}rences
internationales comme le S3C~\citep{Courville+al-2011} ou le
CAE~\citep{Rifai+al-2011}. Le pipeline pr\'{e}sent\'{e} ici a aussi \'{e}t\'{e}
utilis\'{e} pour obtenir une meilleure repr\'{e}sentation avec une
r\'{e}duction de dimensionnalit\'{e} cons\'{e}quente dans le second article
(Chapitre \ref{chap:ob}) de cette dissertation. 

\section{R\'{e}cents d\'{e}veloppements}

Avec la r\'{e}cente mise en avant de l'apprentissage supervis\'{e} et de ses
succ\`{e}s, l'apprentissage non supervis\'{e} est un peu mis en retrait
m\^{e}me si cela reste le graal pour de nombreux chercheurs \'{e}tant donn\'{e}
la quantit\'{e} massive de donnn\'{e}es non labell\'{e}es disponible via
internet. Cela a surtout permis de f\'{e}d\'{e}rer une \'{e}quipe de recherche
avec qui j'ai pu travailler sur d'autres projets. Dans le futur, j'esp\`{e}re
pouvoir continuer \`{a} perp\'{e}tuer ces riches collaborations.
